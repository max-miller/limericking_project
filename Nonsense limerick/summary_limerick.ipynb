{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import cmudict\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import string\n",
    "from newsapi import NewsApiClient\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy import displacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this notebook will be working on taking summaries made up of the indicative sentences from a text and trying to maniuplate them so they can be fit into a limerick type form. These sentences are likely to be long, made up of multiple clauses. I'm going to try to assemble some rules based approaches to extract sub-sentences. Perhaps simply throwing out the subordinate clauses or paring down sentences by removing some auxillary words.\n",
    "\n",
    "First some auxillary functions that I'm copying in from elsewhere. I will definitely need to:\n",
    "1. scrape out news text\n",
    "2. parse the text appropriately so that I can:\n",
    "3. run it through my text summarizer and extract the key sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_api = 'key goes here'\n",
    "alt_key = 'key goes here'\n",
    "\n",
    "def scrape_articles_text(url):\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    req = session.get(url)\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "\n",
    "    paragraph_tags = soup.find_all('p', class_= 'css-exrw3m evys1bk0')\n",
    "    if paragraph_tags == []:\n",
    "        paragraph_tags = soup.find_all('p', itemprop = 'articleBody')\n",
    "\n",
    "    article = ''\n",
    "    for p in paragraph_tags:\n",
    "        article = article + ' ' + p.get_text()\n",
    "\n",
    "    # Clean article replacing unicode characters\n",
    "    article = article.replace(u'\\u2018', u\"'\").replace(u'\\u2019', u\"'\").replace(u'\\u201c', u'\"').replace(u'\\u201d', u'\"')\n",
    "\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_sent_parser(text):\n",
    "    temp_sentences = []\n",
    "    #using SpaCy to parse the text for sentences\n",
    "    text = nlp(text)\n",
    "    #unfortunately will need to reconvert back into strings\n",
    "    for sent in text.sents:\n",
    "        temp = str()\n",
    "        for token in sent:\n",
    "            temp += token.text\n",
    "            temp += ' '\n",
    "        temp_sentences.append(temp)\n",
    "    #Lastly cutting out repeated sentences, to get rid of things like 'subscribe here'\n",
    "    #That come up depending on where you've scraped the text\n",
    "    indices_to_avoid = []\n",
    "    #first identify where the repeated sentences are\n",
    "    for n in range(0,len(temp_sentences)):\n",
    "        for i in range(n+1,len(temp_sentences)):\n",
    "            if temp_sentences[n] == temp_sentences[i]:\n",
    "                indices_to_avoid.append(n)\n",
    "                indices_to_avoid.append(i)\n",
    "    sentences = []\n",
    "    #and then exclude them\n",
    "    for n in range(0,len(temp_sentences)):\n",
    "        if n not in indices_to_avoid:\n",
    "            sentences.append(temp_sentences[n])\n",
    "    return sentences\n",
    "\n",
    "def sent_comparer(sentence_list):\n",
    "    #sklearn vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    transformed = vectorizer.fit_transform(sentence_list)\n",
    "    #Using cosine similarity on the whole list of vectors produces a matrix\n",
    "    #where each sentence's vector is compared to every other sentence\n",
    "    similars = cosine_similarity(transformed,transformed)\n",
    "    #now we collapse into single values\n",
    "    averages = []\n",
    "    for i in similars:\n",
    "        averages.append(i.mean())\n",
    "    #And return the indices of the highest values\n",
    "    #Sorted by index, so that our summary is chronological\n",
    "    n_sents = int(len(sentence_list)**.5)\n",
    "#    sent_indices = sorted(list(np.argsort(averages)[-n_sents:]))\n",
    "    sent_indices = list(np.argsort(averages)[-n_sents:])\n",
    "    return sent_indices\n",
    "\n",
    "def summarizer(text):\n",
    "    sentence_list = text_sent_parser(text)\n",
    "    summary_indices = sent_comparer(sentence_list)\n",
    "    return [sentence_list[n] for n in summary_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, here's an example article. When I first looked at the NYT homepage, the only article that seemed to be not entirely depressing was this one about a possible way to make small amounts of renewable power at night.\n",
    "\n",
    "For this example, I'll work with the sentence identified as being most similar with the rest of the sentences in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the paper , Dr. Raman described how the device , when connected to a voltage converter , was able to power a white LED . ',\n",
       " 'Earlier this year , they also tested an infrared photodiode , similar to the technology used in most solar cells but which uses warmth , not sunlight , to generate wisps of electricity in the darkness . ',\n",
       " 'The village was not equipped with electricity , and Dr. Raman , an electrical engineer at the University of California , Los Angeles , was unaware he was in a village until he heard the voices of shadowed human figures . ',\n",
       " 'At its heart is an off - the shelf gadget called a thermoelectric generator , which uses the difference in temperature between opposite sides of the device to generate a current . ',\n",
       " 'This is a neat combination of radiative cooling — a technique where Raman has pioneered real working devices — with thermoelectric materials that generate electricity if one side is hotter than the other side , \" said Ellen D. Williams , a physics professor at the University of Maryland and a former director of the Department of Energy \\'s Advanced Research Projects Agency - Energy . ',\n",
       " 'The core enabling feature of this device is that it can cool down , \" Dr. Raman said . ',\n",
       " \"Dr. Raman wondered whether he could use all that darkness to make something to light it up , not unlike the way that solar panels generate electricity from the sun 's heat and light .   \"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.nytimes.com/2019/09/12/science/solar-energy-power-electricity.html'\n",
    "text = scrape_articles_text(url)\n",
    "\n",
    "summary = summarizer(text)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = nlp(summary[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dr. Raman wondered whether he could use all that darkness to make something to light it up , not unlike the way that solar panels generate electricity from the sun 's heat and light .   "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is sort of a complicated sentence when you think about it! We have most of the actual content of the sentence in subordinate clauses - the core of the independent clause is really just \"Dr. Rman wondered\", which illustrates both the difficulty of compressing news-speech into short summaries and the limitations of each line of the limerick form, since those three words already take up 6 syllables.\n",
    "\n",
    "Mapping out the parts of speech really illustrate the challenges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: Dr.             POS: PROPN      NNP   compound compound\n",
      "word: Raman           POS: PROPN      NNP   nsubj   nominal subject\n",
      "word: wondered        POS: VERB       VBD   ROOT    None\n",
      "word: whether         POS: ADP        IN    mark    marker\n",
      "word: he              POS: PRON       PRP   nsubj   nominal subject\n",
      "word: could           POS: VERB       MD    aux     auxiliary\n",
      "word: use             POS: VERB       VB    ccomp   clausal complement\n",
      "word: all             POS: DET        DT    predet  None\n",
      "word: that            POS: DET        DT    det     determiner\n",
      "word: darkness        POS: NOUN       NN    dobj    direct object\n",
      "word: to              POS: PART       TO    aux     auxiliary\n",
      "word: make            POS: VERB       VB    xcomp   open clausal complement\n",
      "word: something       POS: NOUN       NN    dobj    direct object\n",
      "word: to              POS: PART       TO    aux     auxiliary\n",
      "word: light           POS: VERB       VB    relcl   relative clause modifier\n",
      "word: it              POS: PRON       PRP   dobj    direct object\n",
      "word: up              POS: PART       RP    prt     particle\n",
      "word: ,               POS: PUNCT      ,     punct   punctuation\n",
      "word: not             POS: ADV        RB    neg     negation modifier\n",
      "word: unlike          POS: ADP        IN    prep    prepositional modifier\n",
      "word: the             POS: DET        DT    det     determiner\n",
      "word: way             POS: NOUN       NN    pobj    object of preposition\n",
      "word: that            POS: DET        WDT   advmod  adverbial modifier\n",
      "word: solar           POS: ADJ        JJ    amod    adjectival modifier\n",
      "word: panels          POS: NOUN       NNS   nsubj   nominal subject\n",
      "word: generate        POS: VERB       VBP   relcl   relative clause modifier\n",
      "word: electricity     POS: NOUN       NN    dobj    direct object\n",
      "word: from            POS: ADP        IN    prep    prepositional modifier\n",
      "word: the             POS: DET        DT    det     determiner\n",
      "word: sun             POS: NOUN       NN    poss    possession modifier\n",
      "word: 's              POS: PART       POS   case    case marking\n",
      "word: heat            POS: NOUN       NN    pobj    object of preposition\n",
      "word: and             POS: CCONJ      CC    cc      coordinating conjunction\n",
      "word: light           POS: NOUN       NN    conj    conjunct\n",
      "word: .               POS: PUNCT      .     punct   punctuation\n",
      "word:                 POS: SPACE      _SP           None\n"
     ]
    }
   ],
   "source": [
    "for token in example:\n",
    "    print(f'word: {token.text:{15}} POS: {token.pos_:{10}} {token.tag_:{5}} {token.dep_:{7}} {spacy.explain(token.dep_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"fdef0d4ebe9040c892b53918f051e186-0\" class=\"displacy\" width=\"6000\" height=\"749.5\" direction=\"ltr\" style=\"max-width: none; height: 749.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Dr.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Raman</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">wondered</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">whether</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">he</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">could</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">use</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">all</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">darkness</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">make</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">something</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">light</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">up ,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">not</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">unlike</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">way</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">that</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">solar</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">panels</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">generate</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">electricity</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">from</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">sun</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">heat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">light .</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">  </tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-0\" stroke-width=\"2px\" d=\"M70,614.5 C70,527.0 195.0,527.0 195.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,616.5 L62,604.5 78,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-1\" stroke-width=\"2px\" d=\"M245,614.5 C245,527.0 370.0,527.0 370.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,616.5 L237,604.5 253,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-2\" stroke-width=\"2px\" d=\"M595,614.5 C595,352.0 1080.0,352.0 1080.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,616.5 L587,604.5 603,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-3\" stroke-width=\"2px\" d=\"M770,614.5 C770,439.5 1075.0,439.5 1075.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,616.5 L762,604.5 778,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-4\" stroke-width=\"2px\" d=\"M945,614.5 C945,527.0 1070.0,527.0 1070.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,616.5 L937,604.5 953,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-5\" stroke-width=\"2px\" d=\"M420,614.5 C420,264.5 1085.0,264.5 1085.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1085.0,616.5 L1093.0,604.5 1077.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-6\" stroke-width=\"2px\" d=\"M1295,614.5 C1295,439.5 1600.0,439.5 1600.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">predet</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,616.5 L1287,604.5 1303,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-7\" stroke-width=\"2px\" d=\"M1470,614.5 C1470,527.0 1595.0,527.0 1595.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,616.5 L1462,604.5 1478,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-8\" stroke-width=\"2px\" d=\"M1120,614.5 C1120,352.0 1605.0,352.0 1605.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1605.0,616.5 L1613.0,604.5 1597.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-9\" stroke-width=\"2px\" d=\"M1820,614.5 C1820,527.0 1945.0,527.0 1945.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,616.5 L1812,604.5 1828,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-10\" stroke-width=\"2px\" d=\"M1120,614.5 C1120,177.0 1965.0,177.0 1965.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1965.0,616.5 L1973.0,604.5 1957.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-11\" stroke-width=\"2px\" d=\"M1995,614.5 C1995,527.0 2120.0,527.0 2120.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2120.0,616.5 L2128.0,604.5 2112.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-12\" stroke-width=\"2px\" d=\"M2345,614.5 C2345,527.0 2470.0,527.0 2470.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,616.5 L2337,604.5 2353,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-13\" stroke-width=\"2px\" d=\"M2170,614.5 C2170,439.5 2475.0,439.5 2475.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2475.0,616.5 L2483.0,604.5 2467.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-14\" stroke-width=\"2px\" d=\"M2520,614.5 C2520,527.0 2645.0,527.0 2645.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2645.0,616.5 L2653.0,604.5 2637.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-15\" stroke-width=\"2px\" d=\"M2520,614.5 C2520,439.5 2825.0,439.5 2825.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prt</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2825.0,616.5 L2833.0,604.5 2817.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-16\" stroke-width=\"2px\" d=\"M3045,614.5 C3045,527.0 3170.0,527.0 3170.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3045,616.5 L3037,604.5 3053,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-17\" stroke-width=\"2px\" d=\"M1120,614.5 C1120,89.5 3195.0,89.5 3195.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3195.0,616.5 L3203.0,604.5 3187.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-18\" stroke-width=\"2px\" d=\"M3395,614.5 C3395,527.0 3520.0,527.0 3520.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3395,616.5 L3387,604.5 3403,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-19\" stroke-width=\"2px\" d=\"M3220,614.5 C3220,439.5 3525.0,439.5 3525.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3525.0,616.5 L3533.0,604.5 3517.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-20\" stroke-width=\"2px\" d=\"M3745,614.5 C3745,352.0 4230.0,352.0 4230.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3745,616.5 L3737,604.5 3753,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-21\" stroke-width=\"2px\" d=\"M3920,614.5 C3920,527.0 4045.0,527.0 4045.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3920,616.5 L3912,604.5 3928,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-22\" stroke-width=\"2px\" d=\"M4095,614.5 C4095,527.0 4220.0,527.0 4220.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4095,616.5 L4087,604.5 4103,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-23\" stroke-width=\"2px\" d=\"M3570,614.5 C3570,264.5 4235.0,264.5 4235.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4235.0,616.5 L4243.0,604.5 4227.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-24\" stroke-width=\"2px\" d=\"M4270,614.5 C4270,527.0 4395.0,527.0 4395.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4395.0,616.5 L4403.0,604.5 4387.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-25\" stroke-width=\"2px\" d=\"M4270,614.5 C4270,439.5 4575.0,439.5 4575.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4575.0,616.5 L4583.0,604.5 4567.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-26\" stroke-width=\"2px\" d=\"M4795,614.5 C4795,527.0 4920.0,527.0 4920.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4795,616.5 L4787,604.5 4803,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-27\" stroke-width=\"2px\" d=\"M4970,614.5 C4970,439.5 5275.0,439.5 5275.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4970,616.5 L4962,604.5 4978,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-28\" stroke-width=\"2px\" d=\"M4970,614.5 C4970,527.0 5095.0,527.0 5095.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5095.0,616.5 L5103.0,604.5 5087.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-29\" stroke-width=\"2px\" d=\"M4620,614.5 C4620,264.5 5285.0,264.5 5285.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5285.0,616.5 L5293.0,604.5 5277.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-30\" stroke-width=\"2px\" d=\"M5320,614.5 C5320,527.0 5445.0,527.0 5445.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5445.0,616.5 L5453.0,604.5 5437.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-31\" stroke-width=\"2px\" d=\"M420,614.5 C420,2.0 5650.0,2.0 5650.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5650.0,616.5 L5658.0,604.5 5642.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-fdef0d4ebe9040c892b53918f051e186-0-32\" stroke-width=\"2px\" d=\"M5670,614.5 C5670,527.0 5795.0,527.0 5795.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-fdef0d4ebe9040c892b53918f051e186-0-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M5795.0,616.5 L5803.0,604.5 5787.0,604.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the different ways we might extract useful fragments, that both looked grammatical and contained actual content? If I were tasked with that challenge, I would think of things like \"he could use all that darkness\", \"solar panels generate\" or even just \"generate electricity\".\n",
    "\n",
    "The added challenge is then making sure that each of these fragments conforms to either the 5 or 7 syllable line lengths. My thinking is that first you create a list of acceptable sub-clauses, taking each verb, say, and extracting it's appropriate N-V-O phrase and then you prune these down in various ways, first cutting extraneous adjectives, say, or chopping off the object.\n",
    "\n",
    "You could build up a long list of these sub-parts and then simply search all the possible permutations to look for any rhymes that naturally occured. That just might work on a sufficiently long article! If not, you could then maybe do something similar on multiple articles and build a summary limerick of the news that has a line from each from multiple stories.\n",
    "\n",
    "Spacy conveniently groups noun chunks together, but doesn't do something similar for 'verb-phrases'. I think the first step is a function that will take in a noun and search for all the appropriate others parts of the phrase using the dependencies.\n",
    "\n",
    "Spacy has a good sense of sentence structure, but unfortunately for my purposes, the tree structure into which the sentence is parsed is not super helpful, since the sub-tree for the main verb is essentially the whole sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wondered\n",
      "use\n",
      "generate\n"
     ]
    }
   ],
   "source": [
    "noun_index = []\n",
    "for n in range(0,len(example)):\n",
    "    if example[n].dep_ == 'nsubj':\n",
    "        noun_index.append(n)\n",
    "        \n",
    "for index in noun_index:\n",
    "    print(example[index].head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Raman\n",
      "wondered\n",
      "whether\n",
      "he\n",
      "could\n",
      "use\n",
      "all\n",
      "that\n",
      "darkness\n",
      "to\n",
      "make\n",
      "something\n",
      "to\n",
      "light\n",
      "it\n",
      "up\n",
      ",\n",
      "not\n",
      "unlike\n",
      "the\n",
      "way\n",
      "that\n",
      "solar\n",
      "panels\n",
      "generate\n",
      "electricity\n",
      "from\n",
      "the\n",
      "sun\n",
      "'s\n",
      "heat\n",
      "and\n",
      "light\n",
      ".\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for token in example[2].subtree:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I can build on the semi-recursive nature of the structure however. I'll parse the sentence from the bottom up, and then I can keep the different verb groups distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whether\n",
      "he\n",
      "could\n",
      "use\n",
      "all\n",
      "that\n",
      "darkness\n",
      "to\n",
      "make\n",
      "something\n",
      "to\n",
      "light\n",
      "it\n",
      "up\n",
      ",\n",
      "not\n",
      "unlike\n",
      "the\n",
      "way\n",
      "that\n",
      "solar\n",
      "panels\n",
      "generate\n",
      "electricity\n",
      "from\n",
      "the\n",
      "sun\n",
      "'s\n",
      "heat\n",
      "and\n",
      "light\n"
     ]
    }
   ],
   "source": [
    "for token in example[6].subtree:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n",
      "make\n",
      "something\n",
      "to\n",
      "light\n",
      "it\n",
      "up\n",
      ",\n"
     ]
    }
   ],
   "source": [
    "for token in example[11].subtree:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Raman wondered whether he could use all that darkness to make something to light it up , not unlike the way that solar panels generate electricity from the sun 's heat and light .   \n",
      "could\n",
      "whether he could use all that darkness to make something to light it up , not unlike the way that solar panels generate electricity from the sun 's heat and light\n",
      "to make something to light it up ,\n",
      "to light it up\n",
      "that solar panels generate electricity from the sun 's heat and light\n"
     ]
    }
   ],
   "source": [
    "#Let's gather up all the verbs\n",
    "verb_index = []\n",
    "for n in range(0,len(example)):\n",
    "    if example[n].pos_ == 'VERB':\n",
    "        verb_index.append(n)\n",
    "        \n",
    "#and see what sort of subtrees they have        \n",
    "for index in verb_index:\n",
    "    print(' '.join([token.text for token in example[index].subtree]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Raman wondered whether he\n",
      "\n",
      "whether he could use all that darkness\n",
      "to make something\n",
      "to light it up\n",
      "that solar panels generate electricity from the sun 's heat and light\n"
     ]
    }
   ],
   "source": [
    "#Let's try breaking apart the tree by making cuts where the next sub tree starts\n",
    "for n in range(0,len(verb_index)-1):\n",
    "    index = verb_index[n]\n",
    "    end_i = example[verb_index[n+1]].left_edge.i\n",
    "    print(' '.join([token.text for token in example[index].subtree if token.i < end_i]))\n",
    "print(' '.join([token.text for token in example[verb_index[-1]].subtree]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge here is the nested/overlapping nature of the tree. The word \"could\" is a subtree unto itself, as an auxilliary in the phrase \"whether he could use\". First task is probably to simply throw away any sub trees that are that short.\n",
    "\n",
    "I also want to look for a way to break out noun phrases, not just the chunks that spacy identifies. Spacy captures adjectives and articles, but doesn't keep things joined by a conjuction together. I want to automatically pull out \"the sun's heat and light\" as one phrase. So far the only instance I know I want to overcome is this one, so it should be easy to fix.\n",
    "\n",
    "First I need to bring my pronunciation parsers back in so I can also test these things for syllable length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK pronunciation dictionary to search for length (and also rhymes later on)\n",
    "entries = nltk.corpus.cmudict.entries()\n",
    "pron_dict = {}\n",
    "for entry in entries:\n",
    "    pron_dict[entry[0]]=entry[1]\n",
    "\n",
    "def word_pronouncer(word):\n",
    "    pron = pron_dict[word.lower()]\n",
    "    stresses = str()\n",
    "    for phoneme in pron:\n",
    "        if phoneme[-1].isdigit():\n",
    "            #NLTK has markings of 0 for unstressed and 1 and 2 for stressed (primary and secondary)\n",
    "            if phoneme[-1] == '0':\n",
    "                stresses += phoneme[-1]\n",
    "            else:\n",
    "                stresses += '1'\n",
    "    return {'stresses':stresses, 'syllables':len(stresses)}\n",
    "\n",
    "def span_syllables(span):\n",
    "    syllables = 0\n",
    "    for n in range(0,len(span)):\n",
    "        #One time fix to handle spacy breaking out the possisve 's and \n",
    "        #it adding syllables to the overall count\n",
    "        if span[n].text.lower() == \"'s\":\n",
    "            pass\n",
    "        elif span[n].pos_ != 'PUNCT':\n",
    "            syllables += word_pronouncer(span[n].text.lower())['syllables']\n",
    "    return syllables\n",
    "\n",
    "\n",
    "#Challenge here when the text contains words not in the pronunciation dictionary!\n",
    "#I'm currently using this alternate version that essentially disregards any span with a word it can't find\n",
    "# def span_syllables(span):\n",
    "#     syllables = 0\n",
    "#     for n in range(0,len(span)):\n",
    "#         #One time fix to handle spacy breaking out the possisve 's and \n",
    "#         #it adding syllables to the overall count\n",
    "#         if span[n].text.lower() == \"'s\":\n",
    "#             pass\n",
    "#         elif span[n].pos_ != 'PUNCT':\n",
    "#             try:\n",
    "#                 syllables += word_pronouncer(span[n].text.lower())['syllables']\n",
    "#             except:\n",
    "#                 return 0\n",
    "#     return syllables\n",
    "\n",
    "\n",
    "#Here's another version that also takes into account the stresses in case I get there\n",
    "def span_syllables_meter(span):\n",
    "    syllables = 0\n",
    "    temp = []\n",
    "    for n in range(0,len(span)):\n",
    "        temp.append(word_pronouncer(span[n].text.lower()))\n",
    "    stresses = str()\n",
    "    for item in temp:\n",
    "        stresses += item['stresses']\n",
    "    return {'stresses':stresses,'syllables':len(stresses)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conjuction(text,noun_chunk):\n",
    "    if text[noun_chunk.end+1].tag == 'CC':\n",
    "        return True\n",
    "\n",
    "def noun_phrase_extract(text):\n",
    "    phrases = []\n",
    "    chunks = [chunk for chunk in text.noun_chunks]\n",
    "    for n in range(0,len(chunks)):\n",
    "        if span_syllables(chunks[n]) == 5 or span_syllables(chunks[n]) == 7:\n",
    "            phrases.append(chunks[n])\n",
    "        if chunks[n].conjuncts != ():\n",
    "            end = max([span.i for span in chunks[n].conjuncts])+1\n",
    "            temp = text[chunks[n].start:end]\n",
    "            if span_syllables(temp) == 5 or span_syllables(temp) == 7:\n",
    "                   phrases.append(temp)\n",
    "    return [phrase.text for phrase in phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[electricity, the sun 's heat and light]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_phrase_extract(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now to handle the verb phrases.\n",
    "1. compile master list of all spans that make sense\n",
    "2. add any that align syllable wise to a running list\n",
    "3. throw out any that are far too short\n",
    "4. consider ways to pare down longer phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verb_spans(text):\n",
    "    verb_index = []\n",
    "    for n in range(0,len(example)):\n",
    "        if example[n].pos_ == 'VERB':\n",
    "            verb_index.append(n)\n",
    "\n",
    "    sub_spans = []\n",
    "    for n in range(0,len(verb_index)-1):\n",
    "        index = verb_index[n]\n",
    "        end_i = example[verb_index[n+1]].left_edge.i\n",
    "        temp = text[min([token.i for token in text[index].subtree]):end_i]\n",
    "        if len(temp) > 0:\n",
    "            sub_spans.append(temp)\n",
    "    sub_spans.append(text[min([token.i for token in text[verb_index[-1]].subtree]):\n",
    "                          max([token.i for token in text[verb_index[-1]].subtree])])\n",
    "    return sub_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dr. Raman wondered whether he,\n",
       " whether he could use all that darkness,\n",
       " to make something,\n",
       " to light it up , not unlike the way,\n",
       " that solar panels generate electricity from the sun 's heat and]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_spans(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we pare these fragments down if need be? What's the bare S-V-O structure minimum? If we're only one or two syllables too long, we should try a minor fix, if we're way over, try paring all the way back\n",
    "1. Get rid of initial auxilliaries (to, whether)\n",
    "2. Pare down descriptors of children in the grammatical structure (strip out 'all that' from 'use all that darkness'\n",
    "3. Is there a smart way to remove something like the 'dr' from Dr Raman's name?\n",
    "4. S-V-O\n",
    "5. S-V\n",
    "6. V-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_phrase_subj(span):\n",
    "    for token in span:\n",
    "        if token.dep_ == 'nsubj':\n",
    "            subj = token\n",
    "    chunks = [chunk for chunk in span.noun_chunks]\n",
    "    for chunk in chunks:\n",
    "        if subj in chunk:\n",
    "            return chunk.text\n",
    "        \n",
    "def find_phrase_obj(span):\n",
    "    dependencies = [token.dep_ for token in span]\n",
    "    if 'dobj' not in dependencies:\n",
    "        return ''\n",
    "    for token in span:\n",
    "        if token.dep_ == 'dobj':\n",
    "            subj = token\n",
    "    chunks = [chunk for chunk in span.noun_chunks]\n",
    "    for chunk in chunks:\n",
    "        if subj in chunk:\n",
    "            return chunk.text\n",
    "\n",
    "def find_verb(span):\n",
    "    for token in span:\n",
    "        if token.pos_ == 'VERB':\n",
    "            return token.text\n",
    "        \n",
    "def count_adj(span):\n",
    "    poses = [token.pos_ for token in span]\n",
    "    return poses.count('ADJ')\n",
    "\n",
    "def drop_adj(span):\n",
    "    poses = [token.pos_ for token in span]\n",
    "    index = poses.index('ADJ')\n",
    "    if index == 0:\n",
    "        return span[1:]\n",
    "    else:\n",
    "        return nlp(span[:index].text+' '+span[index+1:].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "that panels generate electricity from the sun 's heat and"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_adj(spans[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_shortener(span):\n",
    "    options = []\n",
    "    if span_syllables(span) < 5:\n",
    "        return options\n",
    "    dependencies = [token.dep_ for token in span]\n",
    "    if dependencies[0] == 'aux':\n",
    "        if 'compound' in dependencies:\n",
    "            temp = nlp(span[1:dependencies.index('compound')].text+' '+span[dependencies.index('compound')].text)\n",
    "            if span_syllables(temp) == 5 or span_syllables(temp) == 7:\n",
    "                options.append(temp)\n",
    "        temp = span[1:]\n",
    "        if span_syllables(temp) == 5 or span_syllables(temp) == 7:\n",
    "            options.append(temp)\n",
    "    if 'compound' in dependencies:\n",
    "        if dependencies.index('compound') == 0:\n",
    "            temp = span[1:]\n",
    "        else:\n",
    "            temp = nlp(span[:dependencies.index('compound')].text+' '+span[dependencies.index('compound')].text)\n",
    "        if span_syllables(temp) == 5 or span_syllables(temp) == 7:\n",
    "            options.append(temp)\n",
    "    \n",
    "    temp = span\n",
    "    for n in range(0,count_adj(span)):\n",
    "        temp = drop_adj(temp)\n",
    "        if span_syllables(temp) == 5 or span_syllables(temp) == 7:\n",
    "            options.append(temp)\n",
    "    try:        \n",
    "        temp = nlp(find_phrase_subj(span)+' '+find_verb(span)+' '+find_phrase_obj(span))\n",
    "        if span_syllables(temp) == 5 or span_syllables(temp) == 7:\n",
    "            options.append(temp)\n",
    "        if count_adj(temp)>0:\n",
    "            for n in range(0,count_adj(temp)):\n",
    "                temp = drop_adj(temp)\n",
    "                if span_syllables(temp) == 5 or span_syllables(temp) == 7:\n",
    "                    options.append(temp)\n",
    "    \n",
    "    \n",
    "        temp = nlp(find_phrase_subj(span)+' '+find_verb(span))\n",
    "        if span_syllables(temp) == 5 or span_syllables(temp) == 7:\n",
    "            options.append(temp)\n",
    "        if count_adj(temp)>0:\n",
    "            for n in range(0,count_adj(temp)):\n",
    "                temp = drop_adj(temp)\n",
    "                if span_syllables(temp) == 5 or span_syllables(temp) == 7:\n",
    "                    options.append(temp)\n",
    "    \n",
    "        temp = nlp(find_verb(span)+' '+find_phrase_obj(span))\n",
    "        if span_syllables(temp) == 5 or span_syllables(temp) == 7:\n",
    "            options.append(temp)\n",
    "        if count_adj(temp)>0:\n",
    "            for n in range(0,count_adj(temp)):\n",
    "                temp = drop_adj(temp)\n",
    "                if span_syllables(temp) == 5 or span_syllables(temp) == 7:\n",
    "                    options.append(temp)\n",
    "    except:\n",
    "        pass\n",
    "    return [option.text for option in options]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Raman wondered whether he]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_shortener(spans[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[solar panels generate, panels generate]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_shortener(spans[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verb_phrase_extract(text):\n",
    "    phrases = []\n",
    "    spans = verb_spans(text)\n",
    "    for span in spans:\n",
    "        if span_syllables(span) == (5 or 7):\n",
    "            phrases.append(span.text)\n",
    "        phrases+=phrase_shortener(span)\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Raman wondered whether he,\n",
       " could all that darkness,\n",
       " solar panels generate,\n",
       " panels generate]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_phrase_extract(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_phrases(text):\n",
    "    phrases = []\n",
    "    phrases += noun_phrase_extract(text)\n",
    "    phrases += verb_phrase_extract(text)\n",
    "    return phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[electricity,\n",
       " the sun 's heat and light,\n",
       " Raman wondered whether he,\n",
       " could all that darkness,\n",
       " solar panels generate,\n",
       " panels generate]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_all_phrases(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now to assemble a limerick of sorts. I don't know how many possible rhyming lines we're actually going get in any given piece, so first I'm going to parse all sentences together for any usable phrases, then I'll assemble an overall rhyming list and hope that I actually have some hits. With only a handful of lines being created from any given sentence in the text, however, I don't know if I'm super sanguine..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text_phrases(text):\n",
    "    sentences = text_sent_parser(text)\n",
    "    \n",
    "    phrases = []\n",
    "    for sentence in sentences:\n",
    "        span = nlp(sentence.strip())\n",
    "        try:\n",
    "            phrases += find_all_phrases(span)\n",
    "        except:\n",
    "            pass\n",
    "    syllable_dict = {5:[],7:[]}\n",
    "    for phrase in set(phrases):\n",
    "        temp = nlp(phrase)\n",
    "        if span_syllables(temp) == 5:\n",
    "            syllable_dict[5].append(temp)\n",
    "        else:\n",
    "            syllable_dict[7].append(temp)\n",
    "    return syllable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: [research published on,\n",
       "  described a device,\n",
       "  the device described,\n",
       "  electricity,\n",
       "  a combination,\n",
       "  will be improving,\n",
       "  electrical grids,\n",
       "  they are so much heat,\n",
       "  in the journal Joule,\n",
       "  no clouds are present,\n",
       "  an idea came,\n",
       "  panels generate,\n",
       "  , an electrical,\n",
       "  could all that darkness,\n",
       "  at Stanford and an,\n",
       "  battery storage,\n",
       "  solar - powered lights,\n",
       "  remote areas,\n",
       "  the paper , Dr.,\n",
       "  Ellen D. Williams,\n",
       "  jacket - less people,\n",
       "  Dr. Raman said,\n",
       "  the most common type,\n",
       "  about five minutes,\n",
       "  of Technology,\n",
       "  changing batteries,\n",
       "  an alternative,\n",
       "  Modern scientists,\n",
       "  about three orders,\n",
       "  the device described ,\n",
       "  typical solar,\n",
       "  a materials,\n",
       "  of Earth turns away,\n",
       "  the sun 's heat and light,\n",
       "  us about five,\n",
       "  and Afghanistan,\n",
       "  magnitude than what,\n",
       "  an idea came ,\n",
       "  to trap warmth , objects,\n",
       "  a way to go if,\n",
       "  thousand years ago ,,\n",
       "  the technology,\n",
       "  Jeffrey C. Grossman,\n",
       "  the development,\n",
       "  Dr. Raman said ,\n",
       "  Sierra Leone,\n",
       "  realize we were],\n",
       " 7: [Fan 's team described a device,\n",
       "  solar panels generate,\n",
       "  low - power applications,\n",
       "  the passive cooling effect,\n",
       "  a village in Sierra,\n",
       "  Federico Capasso,\n",
       "  streets and jacket - less people,\n",
       "  a lower temperature,\n",
       "  this passive cooling effect,\n",
       "  its buildings , streets and jacket,\n",
       "  changing batteries changing ,\n",
       "  , because it was completely , \",\n",
       "  Iran and Afghanistan,\n",
       "  its buildings , streets and jacket - ,\n",
       "  the device 's efficiency,\n",
       "  a panel produces what,\n",
       "  changing batteries changing,\n",
       "  Raman wondered whether he]}"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_text_phrases(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = text_sent_parser(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[the technology, electricity]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarizer(text)\n",
    "sentence = nlp(summary[1].strip())\n",
    "find_all_phrases(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Earlier this year , they also tested an infrared photodiode , similar to the technology used in most solar cells but which uses warmth , not sunlight , to generate wisps of electricity in the darkness . '"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def span_syllables(span):\n",
    "    syllables = 0\n",
    "    for n in range(0,len(span)):\n",
    "        #One time fix to handle spacy breaking out the possisve 's and \n",
    "        #it adding syllables to the overall count\n",
    "        if span[n].text.lower() == \"'s\":\n",
    "            pass\n",
    "        elif span[n].pos_ != 'PUNCT':\n",
    "            try:\n",
    "                syllables += word_pronouncer(span[n].text.lower())['syllables']\n",
    "            except:\n",
    "                return 0\n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
